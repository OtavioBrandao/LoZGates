"""
Exemplo de anÃ¡lise dos dados detalhados coletados pelo sistema de logging.
Este script demonstra como extrair insights Ãºteis dos dados para melhorar o LoZ Gates.
"""

import json
import matplotlib.pyplot as plt
import pandas as pd
from collections import Counter, defaultdict
from datetime import datetime
import numpy as np

class LoZGatesDataAnalyzer:
    """Analisador de dados do LoZ Gates para extrair insights de uso."""
    
    def __init__(self, data_file_path: str):
        self.data_file = data_file_path
        self.sessions_data = []
        self.load_data()
    
    def load_data(self):
        """Carrega os dados do arquivo JSON."""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.sessions_data = data.get('sessions', [])
            print(f"ğŸ“Š Carregados {len(self.sessions_data)} sessÃµes para anÃ¡lise")
        except Exception as e:
            print(f"âŒ Erro ao carregar dados: {e}")
            self.sessions_data = []
    
    def analyze_simplification_patterns(self):
        """Analisa padrÃµes na simplificaÃ§Ã£o interativa."""
        print("\n=== ANÃLISE: SIMPLIFICAÃ‡ÃƒO INTERATIVA ===")
        
        all_laws = Counter()
        skip_rates = []
        completion_rates = []
        step_counts = []
        
        for session in self.sessions_data:
            simpl_data = session.get('interactive_simplification', {})
            
            # Leis mais usadas
            laws = simpl_data.get('laws_applied', {})
            all_laws.update(laws)
            
            # Taxa de pulos
            sessions_started = simpl_data.get('sessions_started', 0)
            skips = simpl_data.get('skips_used', 0)
            if sessions_started > 0:
                skip_rates.append(skips / sessions_started)
            
            # Taxa de conclusÃ£o
            completed = simpl_data.get('expressions_completed', 0)
            if sessions_started > 0:
                completion_rates.append(completed / sessions_started)
            
            # Passos por sessÃ£o
            total_steps = simpl_data.get('total_steps', 0)
            if sessions_started > 0:
                step_counts.append(total_steps / sessions_started)
        
        # Resultados
        print("ğŸ† Leis mais aplicadas:")
        for law, count in all_laws.most_common(5):
            print(f"   {law}: {count} aplicaÃ§Ãµes")
        
        if skip_rates:
            avg_skip_rate = np.mean(skip_rates)
            print(f"â­ï¸ Taxa mÃ©dia de pulos: {avg_skip_rate:.2f} pulos/sessÃ£o")
        
        if completion_rates:
            avg_completion = np.mean(completion_rates)
            print(f"âœ… Taxa mÃ©dia de conclusÃ£o: {avg_completion*100:.1f}%")
        
        if step_counts:
            avg_steps = np.mean(step_counts)
            print(f"ğŸ”¢ MÃ©dia de passos por sessÃ£o: {avg_steps:.1f}")
        
        return {
            'most_used_laws': dict(all_laws.most_common(10)),
            'avg_skip_rate': np.mean(skip_rates) if skip_rates else 0,
            'avg_completion_rate': np.mean(completion_rates) if completion_rates else 0,
            'avg_steps_per_session': np.mean(step_counts) if step_counts else 0
        }
    
    def analyze_circuit_building_behavior(self):
        """Analisa comportamento na construÃ§Ã£o de circuitos."""
        print("\n=== ANÃLISE: CIRCUITO INTERATIVO ===")
        
        component_usage = Counter()
        test_attempts = []
        success_rates = []
        deletion_rates = []
        undo_usage = []
        
        for session in self.sessions_data:
            circuit_data = session.get('interactive_circuit', {})
            
            # Uso de componentes
            components = circuit_data.get('components_added', {})
            component_usage.update(components)
            
            # Tentativas de teste
            tests = circuit_data.get('test_attempts', 0)
            sessions_started = circuit_data.get('sessions_started', 0)
            if sessions_started > 0 and tests > 0:
                test_attempts.append(tests / sessions_started)
            
            # Taxa de sucesso
            successful = circuit_data.get('successful_circuits', 0)
            if tests > 0:
                success_rates.append(successful / tests)
            
            # Taxa de deleÃ§Ã£o
            deletions = circuit_data.get('components_deleted', 0)
            total_components = sum(components.values())
            if total_components > 0:
                deletion_rates.append(deletions / total_components)
            
            # Uso de undo
            undos = circuit_data.get('undo_operations', 0)
            if sessions_started > 0:
                undo_usage.append(undos / sessions_started)
        
        # Resultados
        print("ğŸ”§ Componentes mais utilizados:")
        for component, count in component_usage.most_common(5):
            print(f"   {component}: {count} usos")
        
        if test_attempts:
            avg_tests = np.mean(test_attempts)
            print(f"ğŸ§ª MÃ©dia de testes por sessÃ£o: {avg_tests:.1f}")
        
        if success_rates:
            avg_success = np.mean(success_rates)
            print(f"âœ… Taxa mÃ©dia de sucesso: {avg_success*100:.1f}%")
        
        if deletion_rates:
            avg_deletions = np.mean(deletion_rates)
            print(f"ğŸ—‘ï¸ Taxa mÃ©dia de deleÃ§Ãµes: {avg_deletions*100:.1f}% dos componentes")
        
        if undo_usage:
            avg_undos = np.mean(undo_usage)
            print(f"â†©ï¸ MÃ©dia de undos por sessÃ£o: {avg_undos:.1f}")
        
        return {
            'component_popularity': dict(component_usage.most_common()),
            'avg_tests_per_session': np.mean(test_attempts) if test_attempts else 0,
            'avg_success_rate': np.mean(success_rates) if success_rates else 0,
            'avg_deletion_rate': np.mean(deletion_rates) if deletion_rates else 0,
            'avg_undo_usage': np.mean(undo_usage) if undo_usage else 0
        }
    
    def analyze_equivalence_patterns(self):
        """Analisa padrÃµes nas verificaÃ§Ãµes de equivalÃªncia."""
        print("\n=== ANÃLISE: VERIFICAÃ‡ÃƒO DE EQUIVALÃŠNCIA ===")
        
        all_checks = []
        complexity_patterns = []
        
        for session in self.sessions_data:
            equiv_data = session.get('equivalence_analysis', {})
            checks = equiv_data.get('expression_pairs', [])
            all_checks.extend(checks)
        
        if not all_checks:
            print("âš ï¸ Nenhuma verificaÃ§Ã£o de equivalÃªncia encontrada")
            return {}
        
        # AnÃ¡lise dos resultados
        total_checks = len(all_checks)
        equivalent_count = sum(1 for check in all_checks if check.get('result'))
        non_equivalent_count = total_checks - equivalent_count
        
        # AnÃ¡lise de complexidade
        for check in all_checks:
            expr1_len = check.get('expr1_length', 0)
            expr2_len = check.get('expr2_length', 0)
            complexity_diff = abs(expr1_len - expr2_len)
            complexity_patterns.append({
                'diff': complexity_diff,
                'result': check.get('result'),
                'avg_length': (expr1_len + expr2_len) / 2
            })
        
        # SequÃªncia temporal de verificaÃ§Ãµes
        recent_pattern = []
        for check in all_checks[-10:]:  # Ãšltimas 10 verificaÃ§Ãµes
            recent_pattern.append("âœ“" if check.get('result') else "âœ—")
        
        print(f"ğŸ“Š Total de verificaÃ§Ãµes: {total_checks}")
        print(f"âœ… Equivalentes: {equivalent_count} ({equivalent_count/total_checks*100:.1f}%)")
        print(f"âŒ NÃ£o equivalentes: {non_equivalent_count} ({non_equivalent_count/total_checks*100:.1f}%)")
        
        if recent_pattern:
            print(f"ğŸ”„ PadrÃ£o recente: {' '.join(recent_pattern)}")
        
        # AnÃ¡lise de complexidade
        if complexity_patterns:
            avg_complexity_diff = np.mean([p['diff'] for p in complexity_patterns])
            print(f"ğŸ“ DiferenÃ§a mÃ©dia de complexidade: {avg_complexity_diff:.1f} caracteres")
        
        return {
            'total_checks': total_checks,
            'equivalent_rate': equivalent_count / total_checks if total_checks > 0 else 0,
            'avg_complexity_difference': np.mean([p['diff'] for p in complexity_patterns]) if complexity_patterns else 0,
            'recent_pattern': recent_pattern
        }
    
    def analyze_expression_complexity_trends(self):
        """Analisa tendÃªncias de complexidade das expressÃµes."""
        print("\n=== ANÃLISE: COMPLEXIDADE DAS EXPRESSÃ•ES ===")
        
        variable_counts = Counter()
        expression_lengths = Counter()
        operator_usage = {'AND': 0, 'OR': 0, 'NOT': 0}
        
        for session in self.sessions_data:
            patterns = session.get('expression_patterns', {})
            
            # Contagem de variÃ¡veis
            var_counts = patterns.get('variable_counts', {})
            for count, freq in var_counts.items():
                variable_counts[int(count)] += freq
            
            # Comprimentos de expressÃ£o
            lengths = patterns.get('expression_lengths', {})
            for length, freq in lengths.items():
                expression_lengths[int(length)] += freq
            
            # Uso de operadores
            ops = patterns.get('operator_usage', {})
            for op in operator_usage:
                operator_usage[op] += ops.get(op, 0)
        
        # Resultados
        print("ğŸ”¢ DistribuiÃ§Ã£o de variÃ¡veis por expressÃ£o:")
        for var_count in sorted(variable_counts.keys()):
            freq = variable_counts[var_count]
            print(f"   {var_count} variÃ¡veis: {freq} expressÃµes")
        
        print("ğŸ“ DistribuiÃ§Ã£o de tamanhos de expressÃ£o:")
        for length in sorted(expression_lengths.keys())[:10]:  # Top 10
            freq = expression_lengths[length]
            print(f"   {length} caracteres: {freq} expressÃµes")
        
        print("âš¡ PreferÃªncia de operadores:")
        total_ops = sum(operator_usage.values())
        if total_ops > 0:
            for op, count in operator_usage.items():
                percentage = (count / total_ops) * 100
                print(f"   {op}: {count} usos ({percentage:.1f}%)")
        
        return {
            'variable_distribution': dict(variable_counts),
            'length_distribution': dict(expression_lengths),
            'operator_preferences': operator_usage
        }
    
    def analyze_error_patterns(self):
        """Analisa padrÃµes de erros encontrados pelos usuÃ¡rios."""
        print("\n=== ANÃLISE: PADRÃ•ES DE ERROS ===")
        
        total_errors = 0
        sessions_with_errors = 0
        error_types = Counter()
        
        for session in self.sessions_data:
            session_stats = session.get('session_stats', {})
            errors_in_session = session_stats.get('errors_encountered', 0)
            
            total_errors += errors_in_session
            if errors_in_session > 0:
                sessions_with_errors += 1
            
            # Analisa eventos de erro
            events = session.get('events', [])
            for event in events:
                if event.get('type') == 'error_occurred':
                    error_type = event.get('data', {}).get('error_type', 'unknown')
                    error_types[error_type] += 1
        
        total_sessions = len(self.sessions_data)
        
        print(f"âš ï¸ Total de erros: {total_errors}")
        print(f"ğŸ“Š SessÃµes com erros: {sessions_with_errors}/{total_sessions} ({sessions_with_errors/total_sessions*100:.1f}%)")
        
        if error_types:
            print("ğŸ” Tipos de erros mais comuns:")
            for error_type, count in error_types.most_common(5):
                print(f"   {error_type}: {count} ocorrÃªncias")
        
        return {
            'total_errors': total_errors,
            'sessions_with_errors_rate': sessions_with_errors / total_sessions if total_sessions > 0 else 0,
            'common_error_types': dict(error_types.most_common(10))
        }
    
    def analyze_user_engagement(self):
        """Analisa padrÃµes de engajamento dos usuÃ¡rios."""
        print("\n=== ANÃLISE: ENGAJAMENTO DO USUÃRIO ===")
        
        session_durations = []
        events_per_session = []
        feature_usage = Counter()
        
        for session in self.sessions_data:
            duration = session.get('duration_seconds', 0)
            if duration > 0:
                session_durations.append(duration / 60)  # Converte para minutos
            
            events_count = session.get('events_count', 0)
            if events_count > 0:
                events_per_session.append(events_count)
            
            # Conta uso de features
            events = session.get('events', [])
            for event in events:
                if event.get('type') == 'feature_used':
                    feature = event.get('data', {}).get('feature', 'unknown')
                    feature_usage[feature] += 1
        
        # Resultados
        if session_durations:
            avg_duration = np.mean(session_durations)
            median_duration = np.median(session_durations)
            print(f"â±ï¸ DuraÃ§Ã£o mÃ©dia de sessÃ£o: {avg_duration:.1f} minutos")
            print(f"â±ï¸ DuraÃ§Ã£o mediana: {median_duration:.1f} minutos")
        
        if events_per_session:
            avg_events = np.mean(events_per_session)
            print(f"ğŸ¯ MÃ©dia de eventos por sessÃ£o: {avg_events:.1f}")
        
        print("ğŸ† Features mais utilizadas:")
        for feature, count in feature_usage.most_common(5):
            print(f"   {feature}: {count} usos")
        
        return {
            'avg_session_duration_minutes': np.mean(session_durations) if session_durations else 0,
            'median_session_duration_minutes': np.median(session_durations) if session_durations else 0,
            'avg_events_per_session': np.mean(events_per_session) if events_per_session else 0,
            'most_used_features': dict(feature_usage.most_common(10))
        }
    
    def generate_comprehensive_report(self):
        """Gera relatÃ³rio completo de anÃ¡lise."""
        print("ğŸš€ Gerando relatÃ³rio completo de anÃ¡lise do LoZ Gates...")
        print("=" * 60)
        
        report = {
            'analysis_date': datetime.now().isoformat(),
            'total_sessions_analyzed': len(self.sessions_data),
            'simplification_analysis': self.analyze_simplification_patterns(),
            'circuit_analysis': self.analyze_circuit_building_behavior(),
            'equivalence_analysis': self.analyze_equivalence_patterns(),
            'expression_complexity': self.analyze_expression_complexity_trends(),
            'error_patterns': self.analyze_error_patterns(),
            'user_engagement': self.analyze_user_engagement()
        }
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ RESUMO EXECUTIVO:")
        print(f"â€¢ Total de sessÃµes analisadas: {report['total_sessions_analyzed']}")
        
        simpl = report['simplification_analysis']
        if simpl:
            print(f"â€¢ Taxa de conclusÃ£o na simplificaÃ§Ã£o: {simpl.get('avg_completion_rate', 0)*100:.1f}%")
            print(f"â€¢ Passos mÃ©dios por simplificaÃ§Ã£o: {simpl.get('avg_steps_per_session', 0):.1f}")
        
        circuit = report['circuit_analysis']
        if circuit:
            print(f"â€¢ Taxa de sucesso no circuito: {circuit.get('avg_success_rate', 0)*100:.1f}%")
            print(f"â€¢ Testes mÃ©dios por circuito: {circuit.get('avg_tests_per_session', 0):.1f}")
        
        engagement = report['user_engagement']
        if engagement:
            print(f"â€¢ DuraÃ§Ã£o mÃ©dia de sessÃ£o: {engagement.get('avg_session_duration_minutes', 0):.1f} min")
        
        errors = report['error_patterns']
        if errors:
            print(f"â€¢ Taxa de sessÃµes com erro: {errors.get('sessions_with_errors_rate', 0)*100:.1f}%")
        
        return report
    
    def save_report_to_file(self, report, filename="loz_gates_analysis_report.json"):
        """Salva o relatÃ³rio em arquivo JSON."""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ RelatÃ³rio salvo em: {filename}")
        except Exception as e:
            print(f"âŒ Erro ao salvar relatÃ³rio: {e}")

# Exemplo de uso
if __name__ == "__main__":
    # Inicializa o analisador
    analyzer = LoZGatesDataAnalyzer("user_activity_detailed.json")
    
    # Gera anÃ¡lise completa
    report = analyzer.generate_comprehensive_report()
    
    # Salva relatÃ³rio
    analyzer.save_report_to_file(report)
    
    # Exemplos de insights especÃ­ficos que vocÃª pode extrair:
    print("\nğŸ¯ INSIGHTS ESPECÃFICOS PARA MELHORIA:")
    
    # 1. Leis mais difÃ­ceis
    simpl = report.get('simplification_analysis', {})
    laws = simpl.get('most_used_laws', {})
    if laws:
        least_used = sorted(laws.items(), key=lambda x: x[1])[:3]
        print(f"ğŸ“š Leis menos utilizadas (podem precisar de mais explicaÃ§Ã£o):")
        for law, count in least_used:
            print(f"   â€¢ {law}: apenas {count} usos")
    
    # 2. Componentes problemÃ¡ticos no circuito
    circuit = report.get('circuit_analysis', {})
    deletion_rate = circuit.get('avg_deletion_rate', 0)
    if deletion_rate > 0.3:  # Se mais de 30% dos componentes sÃ£o deletados
        print(f"âš ï¸ Alta taxa de deleÃ§Ã£o ({deletion_rate*100:.1f}%) sugere interface confusa")
    
    # 3. PadrÃµes de erro
    errors = report.get('error_patterns', {})
    common_errors = errors.get('common_error_types', {})
    if common_errors:
        print("ğŸ”§ Erros mais comuns que precisam ser corrigidos:")
        for error_type, count in list(common_errors.items())[:3]:
            print(f"   â€¢ {error_type}: {count} ocorrÃªncias")